---
title: "02uzd_Zuperka"
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(repos = c(CRAN = "https://cloud.r-project.org/"))
```
## <br><b> 1) Datu lejupielāde, atarhivēšana un nevajadzīgo dzēšana </b>
```{r 1 / 15 datu lejupielāde, echo=FALSE}
# Lejupielādēju datus
if (!require("httr")) install.packages("httr")

# Lejupielādes funkcija
url <- "https://data.gov.lv/dati/lv/dataset/40014c0a-90f5-42be-afb2-fe3c4b8adf92/resource/392dfb67-eeeb-43c2-b082-35f9cf986128/download/centra.7z"
centra_mezi <- "Centra.7z"
centra_mezi_directory <- "C:/Users/mark7/Documents/MZ_HiQBioDiv_macibas/Uzd02"

download_7z <- function(url, centra_mezi) {
  cat("Lejuplādējam .7z failu...\n")
  httr::GET(url, httr::write_disk(centra_mezi, overwrite = TRUE))
  cat("Lejuplāde pabeigta! ", centra_mezi, "\n")
}

# Atarhivēšanas funkcija
if (!require("archive")) install.packages("archive")

extract_7z <- function(centra_mezi, centra_mezi_directory) {
  cat("Atarhivējam...\n")
  if (!dir.exists(centra_mezi_directory)) dir.create(centra_mezi_directory, recursive = TRUE)
  
  archive::archive_extract(centra_mezi, centra_mezi_directory)
  
  cat("Atarhivēšana pabeigta. Dati saglabāti: ", centra_mezi_directory, "\n")
}

# Izpildu
tryCatch({
  download_7z(url, centra_mezi)
  extract_7z(centra_mezi, centra_mezi_directory)
  
# Dzēšu sākotnējo 7z failu pēc atarhivēšanas
  if (file.exists(centra_mezi)) {
    file.remove(centra_mezi)
    cat("Arhīvs izdzēsts pēc lejupielādes un atarhivēšanas: ", centra_mezi, "\n")
  } else {
    cat("Arhīvs neeksistē: ", centra_mezi, "\n")
  }
}, error = function(e) {
  cat("Radās kļūda: ", e$message, "\n")
})

```
###<br><b> 2) Konvertācija uz geopackage, geoparquet un ESRI File Geodatabase </b>
##<br> 2.1) Ielasu tikai shapefile
```{r 2 / 15 shapefile ielasīšana, echo=FALSE}
#Ielādēju pakotnes

if (!require("sf")) install.packages("sf")
if (!require("arrow")) install.packages("arrow")

extracted_files <- list.files(centra_mezi_directory, full.names = FALSE)

shapefile_name <- "nodala2651.shp"
shapefile_path <- extracted_files[grepl("\\.shp$", extracted_files)]

# Meklējam visus SHP failus
shapefile_files <- extracted_files[grepl("\\.shp$", extracted_files)] #Šim kodam vajadzētu risināt problēmu, ka mapē ir 2 faili ar vienādu nosaukumu, bet dažādiem paplašinājumiem

# Pārbauda, vai atrasts vismaz viens SHP fails
if (length(shapefile_files) == 1) {
  cat("SHP fails atrasts:", shapefile_files, "\n")
  
  tryCatch({
    # Ielasām SHP failu
    nodala_2651_shp <- st_read(shapefile_files)
    cat("SHP ielasīts.\n")
  }, error = function(e) {
    cat("Radās kļūda ielasot SHP failu: ", e$message, "\n")
  })
} else if (length(shapefile_files) == 0) {
  cat("SHP fails nav atrasts.\n")
} else {
  
  # 75. komandlīnija nenostradāja tāpēc izmantoju viltīgu paņēmienu un ielasu lielāko no failiem (loģiski shp apveidfailam vajadzētu būt lielākam par xml failu)
  file_sizes <- file.info(shapefile_files)$size
  largest_file <- shapefile_files[which.max(file_sizes)]
  
  cat("Izvēlēts lielākais fails:", largest_file, "\n")
  
  tryCatch({
    # Ielasām lielāko SHP failu
    nodala_2651_shp <- st_read(largest_file)
    cat("SHP ielasīts.\n")
  }, error = function(e) {
    cat("Radās kļūda ielasot lielāko SHP failu: ", e$message, "\n")
  })
}
```
##<br> 2.2) Konvertēju uz geoparquet
```{r 3 / 15 konvertēšana uz geoparquet, echo=FALSE}

    # Konvertēju uz data frame un drop ģeometriju lai nav kļūdu
    df <- st_drop_geometry(nodala_2651_shp)
    
   
    df$geometry <- st_as_text(st_geometry(nodala_2651_shp))
    
    output_file <- "Nodala_2651.parquet"
    arrow::write_parquet(df, output_file)
    
    cat("Sekmīgi konvertēts uz GeoParquet:", output_file, "\n")
    
 error = function(e) 
    cat("Radās kļūda rakstot GeoParquet failu: ", e$message, "\n")

```
##<br> 2.3) Konvertēju uz geopackage
```{r 4 / 15 konvertēšana uz geopackage, echo=FALSE}
output_gpkg <- "nodala_2651.gpkg"

tryCatch({
  st_write(nodala_2651_shp, output_gpkg)
  cat("GeoPackage fails ir izveidots!\n")
}, error = function(e) {
  cat("Radās kļūda rakstot GeoPackage failu: ", e$message, "\n")
})
```
#<br><b> 3) Aizņemtās diska vietas un ielasīšanas ātrums 10 izmēģinājumos </b>
```{r 5 / 15 aizņemtās vietas un ielasīšanas ātruma pārbaude, echo=FALSE}
# Assuming extracted_files is a vector containing paths to your files
if (!require("microbenchmark", quietly = TRUE)) install.packages("microbenchmark") else library(microbenchmark)

# Search for files with specific extensions (GeoParquet, GeoPackage, Shapefile)
nodala_2651_geoparquet <- list.files(centra_mezi_directory, pattern = "\\.parquet$", full.names = TRUE)
nodala_2651_gpkg <- list.files(centra_mezi_directory, pattern = "\\.gpkg$", full.names = TRUE)

# Refined search for .shp files containing 'nodala_2651' in the name
nodala_2651_shp <- list.files(centra_mezi_directory, pattern = "nodala2651.*\\.shp$", full.names = TRUE)

# Check if files are present and stop with a message if not
if (length(nodala_2651_geoparquet) == 0) stop("No GeoParquet files found!")
if (length(nodala_2651_gpkg) == 0) stop("No GeoPackage files found!")
if (length(nodala_2651_shp) == 0) stop("No matching Shapefile (nodala2651) found!")

# Function to load data into memory
load_data <- function() {
  # Load GeoParquet data
  geoparquet_data <- read_parquet(nodala_2651_geoparquet[1])  # Use the first GeoParquet file
  
  # Load GeoPackage data
  gpkg_data <- st_read(nodala_2651_gpkg[1])  # Use the first GeoPackage file
  
  # Load Shapefile data
  shapefile_data <- st_read(nodala_2651_shp[1])  # Load the first matching Shapefile
  
  list(
    geoparquet_data = geoparquet_data,
    gpkg_data = gpkg_data,
    shapefile_data = shapefile_data
  )
}

# Function to benchmark file read speeds
benchmark_disk_read_speed <- function(tries = 10) {
  # Warm-up reads to stabilize disk caching
  invisible(load_data())  # Load data for warm-up
  
  # Run benchmarks
  results <- lapply(1:tries, function(i) {
    shapefile_benchmark <- microbenchmark(
      read_shapefile = {
        st_read(nodala_2651_shp[1])
      },
      times = 1
    )
    
    geoparquet_benchmark <- microbenchmark(
      read_geoparquet = {
        read_parquet(nodala_2651_geoparquet[1])  # Use the first GeoParquet file
      },
      times = 1
    )
    
    gpkg_benchmark <- microbenchmark(
      read_gpkg = {
        st_read(nodala_2651_gpkg[1])  # Use the first GeoPackage file
      },
      times = 1
    )
    
    data.frame(
      Try = i,
      ShapefileTime = summary(shapefile_benchmark)$median / 1e9,  # Convert to seconds
      GeoPackageTime = summary(gpkg_benchmark)$median / 1e9,  # Convert to seconds
      GeoParquetTime = summary(geoparquet_benchmark)$median / 1e9  # Convert to seconds
    )
  })
  
  return(do.call(rbind, results))
}

# Function to get file sizes in MB
get_file_size_mb <- function(file_paths) {
  file_info <- file.info(file_paths)
  file_sizes <- file_info$size / (1024^2)  # Convert size to MB
  return(file_sizes)
}

# Function to get Shapefile and its associated DBF file size in MB
get_shapefile_and_dbf_size <- function(shp_file) {
  dbf_file <- sub("\\.shp$", ".dbf", shp_file)  # Replace .shp with .dbf
  
  if (file.exists(dbf_file)) {
    shp_size_mb <- get_file_size_mb(shp_file)
    dbf_size_mb <- get_file_size_mb(dbf_file)
    total_size_mb <- shp_size_mb + dbf_size_mb
    return(list(shp_size = shp_size_mb, dbf_size = dbf_size_mb, total_size = total_size_mb))
  } else {
    stop("DBF file not found for the shapefile.")
  }
}

# Get file sizes for each type
shapefile_and_dbf_size <- get_shapefile_and_dbf_size(nodala_2651_shp[1])  # Using the first Shapefile
gpkg_size_mb <- get_file_size_mb(nodala_2651_gpkg)
geoparquet_size_mb <- get_file_size_mb(nodala_2651_geoparquet)

# Print file sizes
cat(sprintf("Shapefile is %.2f MB large, but with the required DBF file, it is %.2f MB large.\n",
            shapefile_and_dbf_size$shp_size, shapefile_and_dbf_size$total_size))
cat(sprintf("GeoPackage is %.2f MB large.\n", gpkg_size_mb))
cat(sprintf("GeoParquet is %.2f MB large.\n", geoparquet_size_mb))

# Run the optimized benchmark
benchmark_results <- benchmark_disk_read_speed(tries = 10)

# Print the benchmarking results
print(benchmark_results)

```
#<br><b> 4) Apvienoju visus centra mežniecības datus</b>
```{r 6 / 15 mežniecības datu apvienošana, echo=FALSE}
output_combine<- "C:/Users/mark7/Documents/MZ_HiQBioDiv_macibas/Uzd02/Centrs_combined.shp"

combine_shapefiles <- function(centra_mezi_directory, Centrs_combined) {
  # List all shapefiles in the folder
  shapefiles <- list.files(centra_mezi_directory, pattern = "\\.shp$", full.names = TRUE)
  
  # Read and combine all shapefiles into one sf object
  combined_sf <- lapply(shapefiles, st_read) %>%
    do.call(rbind, .)
  
  # Convert the 'id' field to character 
combined_sf$id <- as.character(combined_sf$id)

combined_sf_clean <- combined_sf[!st_is_empty(combined_sf), ]

  # Save the combined shapefile
  st_write(combined_sf_clean, output_combine, append=FALSE)
  
  cat("Combined shapefile saved as:", Centrs_combined, "\n")
}

combine_shapefiles(centra_mezi_directory, output_combine)
```
###<br><b> 5) Priežu aprēķini</b>
```{r 7 / 15 priežu īpatsvara aprēķināšana, echo=FALSE}
output_combine <- st_read("C:/Users/mark7/Documents/MZ_HiQBioDiv_macibas/Uzd02/Centrs_combined.shp")

#1) Skaitu priežu īpatsvaru
calculate_prop_priedes <- function(output_combine) {
  # Identificējiet kolonnas ar koku sugām un šķērslaukumiem
  sugu_kolonnas <- c("s10", "s11", "s12", "s13", "s14")
  skerslaukuma_kolonnas <- c("a10", "a11", "a12", "a13", "a14")
  
  # Inicializējiet prop_priedes kolonnu ar nullēm
  output_combine$prop_priedes <- 0
  
  # Cikls, lai izpildītu nosacījumu katram pārim S un A laukam
  for (i in 1:length(sugu_kolonnas)) {
    # Ja S laukā ir "P", pievienojiet attiecīgo A laukā vērtību prop_priedes
    output_combine$prop_priedes <- output_combine$prop_priedes + 
      ifelse(output_combine[[sugu_kolonnas[i]]] == "1", output_combine[[skerslaukuma_kolonnas[i]]], 0)
  }
  
  return(output_combine)
}

# Lietojiet funkciju
output_combine <- calculate_prop_priedes(output_combine)

# Pārbaudiet pirmos ierakstus
head(output_combine)

#2) Atzīmēju PriezuMezi kolonnā 0 vai 1

add_priezu_mezi <- function(output_combine) {
  
  output_combine$PriezuMezi <- ifelse(output_combine$prop_priedes >= 75, 1, 0)
  
  return(output_combine)
}

output_combine <- add_priezu_mezi(output_combine)

head(output_combine)

#3) Apskatos īpatsvaru

# Skaitīt priežu mežu poligonus ar PriezuMezi = 1
count_priezu_mezi_1 <- sum(output_combine$PriezuMezi == 1)

total_polygons <- nrow(output_combine)

Priezu_ipatsvars <- (count_priezu_mezi_1 / total_polygons) * 100

cat("Centra virsmežniecībā ir", count_priezu_mezi_1, "priežu mežu poligoni, kuri veido", round(Priezu_ipatsvars, 2), "% no kopējā poligonu skaita (", total_polygons,").\n")

```
###<br><b> 6) Klasifikācija </b>
<br> Klasifikācijai pirmkārt norādu kuri koki pieder kuram tipam un izveidoju jaunas kollonnas (k_s) (kombinēju atsevišķus kokus koku grupās, balstoties uz interneta resursiem un savām zināšanām) 
```{r 8 / 15 mežu klasifikācija 1 solis - koku kodēšana, echo=FALSE}
# Create a lookup data frame for KODS and NOSAUKUMS
kod_to_nosaukums <- data.frame(
  KODS = c(1, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 35, 61, 62, 63, 64, 65, 66, 67, 68, 69),
  NOSAUKUMS = c("Skujkoku", "Šaurlapju", "Šaurlapju", "Šaurlapju", "Šaurlapju", "Šaurlapju", 
                "Platlapju", "Platlapju", "Platlapju", "Skujkoku", "Skujkoku", "Skujkoku", 
                "Platlapju", "Platlapju", "Platlapju", "Šaurlapju", "Šaurlapju", "Šaurlapju", 
                "Skujkoku", "Skujkoku", "Platlapju", "Šaurlapju", "Šaurlapju", "Šaurlapju", 
                "Skujkoku", "Skujkoku", "Šaurlapju", "Šaurlapju", "Platlapju", "Platlapju", 
                "Platlapju", "Platlapju", "Platlapju", "Šaurlapju", "Šaurlapju", "Šaurlapju", 
                "Šaurlapju")
)

# Convert the columns s10 to s14 to numeric
cols_to_convert <- c("s10", "s11", "s12", "s13", "s14")
output_combine[cols_to_convert] <- lapply(output_combine[cols_to_convert], function(x) as.numeric(as.character(x)))

# Now create the new columns (k_s10, k_s11, ..., k_s14) based on KODS values
for (i in 10:14) {
  # Define the new column name (e.g., k_s10, k_s11, etc.)
  new_col_name <- paste0("k_s", i)
  
  # Create a lookup vector for the KODS to NOSAUKUMS mapping
  k_s_column <- output_combine[[paste0("s", i)]]
  
  # Map the KODS to the corresponding NOSAUKUMS
  output_combine[[new_col_name]] <- sapply(k_s_column, function(kod) {
    if (!is.na(kod) && kod %in% kod_to_nosaukums$KODS) {
      return(kod_to_nosaukums$NOSAUKUMS[kod_to_nosaukums$KODS == kod])
    } else {
      return(0)}})}

# Check the result
head(output_combine)

```
<br> Tālāk summēju A kolonnu summārās vērtības katram koku tipam un izvadu jaunās kolonnās (Skuj_proc utt)
```{r 9 / 15 mežu klasifikācija 2 solis - koku seguma summēšana, echo=FALSE}
# Create the new columns 'Shaur_proc', 'Plat_proc', and 'Skuj_proc'
output_combine$Shaur_proc <- apply(output_combine, 1, function(row) {
  # Initialize sum for Šaurlapju
  sum_shaurlapju <- 0
  
  # Loop over the k_s and a columns to check for Šaurlapju and sum A values
  for (i in 10:14) {
    # Get the A value for the current column
    a_value <- as.numeric(row[paste0("a", i)])
    
    # Only add to the sum if it's a valid number and the tree type matches
    if (!is.na(a_value) && row[paste0("k_s", i)] == "Šaurlapju") {
      sum_shaurlapju <- sum_shaurlapju + a_value
    }
  }
  
  return(sum_shaurlapju)
})

output_combine$Plat_proc <- apply(output_combine, 1, function(row) {
  # Initialize sum for Platlapju
  sum_platlapju <- 0
  
  # Loop over the k_s and a columns to check for Platlapju and sum A values
  for (i in 10:14) {
    # Get the A value for the current column
    a_value <- as.numeric(row[paste0("a", i)])
    
    # Only add to the sum if it's a valid number and the tree type matches
    if (!is.na(a_value) && row[paste0("k_s", i)] == "Platlapju") {
      sum_platlapju <- sum_platlapju + a_value
    }
  }
  
  return(sum_platlapju)
})

output_combine$Skuj_proc <- apply(output_combine, 1, function(row) {
  # Initialize sum for Skujkoku
  sum_skujkoku <- 0
  
  # Loop over the k_s and a columns to check for Skujkoku and sum A values
  for (i in 10:14) {
    # Get the A value for the current column
    a_value <- as.numeric(row[paste0("a", i)])
    
    # Only add to the sum if it's a valid number and the tree type matches
    if (!is.na(a_value) && row[paste0("k_s", i)] == "Skujkoku") {
      sum_skujkoku <- sum_skujkoku + a_value
    }
  }
  
  return(sum_skujkoku)
})

# Check the result
head(output_combine)
```
<br> Iegūstu slāni kurā katram mežam ir parādīts cik % daudz ir skujkoki, platlapji un šaurlapji. Tālāk sāku klasifikāciju un nosaku mežu tipus, par kuriem ir dati tikai par 1 koku sugu, nosaku 20% robežvērtību (Ministru kabineta Meža likums).
```{r 10 / 15 mežu klasifikācija 3 solis - vienkāršu mežu tipu definēšana, echo=FALSE}
# Create the new 'kalk_tips' column based on the conditions
output_combine$kalk_tips <- apply(output_combine, 1, function(row) {
  
  # Check if only one tree type has a valid value greater than or equal to 75 and the other columns are 0
  if (row["Skuj_proc"] >= 20 && row["Plat_proc"] == 0 && row["Shaur_proc"] == 0) {
    return("Skujkoku mežs")
  } else if (row["Plat_proc"] >= 20 && row["Skuj_proc"] == 0 && row["Shaur_proc"] == 0) {
    return("Platlapju mežs")
  } else if (row["Shaur_proc"] >= 20 && row["Skuj_proc"] == 0 && row["Plat_proc"] == 0) {
    return("Šaurlapju mežs")
  } else {
    return(NA)  # For other cases, return NA
  }
})
```
<br> Tad definēju jauktos mežus - mežus, kur starpība starp koku tipiem nav lielāka par 20%, piem. 50% skujkoki un 30% lapu koki tiks atzīmēts kā jaukts mežs. 
```{r 11 / 15 mežu klasifikācija 4 solis - jauktu mežu izdalīšana, echo=FALSE}
output_combine$kalk_tips <- apply(output_combine, 1, function(row) {
  # Skip rows where 'kalk_tips' already has a value
  if (!is.na(row["kalk_tips"])) {
    return(row["kalk_tips"])  # Keep the existing value
  }
  # Convert the relevant columns to numeric
  skuj_proc <- as.numeric(row["Skuj_proc"])
  plat_proc <- as.numeric(row["Plat_proc"])
  shaur_proc <- as.numeric(row["Shaur_proc"])
  
  # Check if the absolute difference between any two values is less than or equal to 20
  if (abs(skuj_proc - plat_proc) <= 20 && skuj_proc > 0 && plat_proc > 0 && shaur_proc == 0) {
    return("Jaukts mežs")
  } else if (abs(shaur_proc - plat_proc) <= 20 && shaur_proc > 0 && plat_proc > 0 && skuj_proc == 0) {
    return("Jaukts mežs")
  } else if (abs(shaur_proc - skuj_proc) <= 20 && shaur_proc > 0 && skuj_proc > 0 && plat_proc == 0) {
    return("Jaukts mežs")
  }})

```
<br> Turpinu klasificēt un ierakstu !nav mežs! tām rindām, kurās kumulatīvais koku segums ir zem 20%
```{r 12 / 15 mežu klasifikācija 5 solis - !nav mežs! izdalīšana, echo=FALSE}
output_combine$kalk_tips <- apply(output_combine, 1, function(row) {
  # Convert to numeric and check if the combined values are less than 20
  skuj_proc <- as.numeric(row["Skuj_proc"])
  plat_proc <- as.numeric(row["Plat_proc"])
  shaurl_proc <- as.numeric(row["Shaur_proc"])

  # If the sum of all tree types is less than 20
  if ((skuj_proc + plat_proc + shaurl_proc) < 20) {
    return("!nav mežs!")
  }
  
  # Return the existing value of kalk_tips if the condition is not met
  return(row["kalk_tips"])
})
```
<br> Atlikuši tikai poligoni, kuros ir vairāk par 20% starpība. Tajos ņemu to meža nosaukumu, kura segums ir lielākais.
```{r 13 / 15 mežu klasifikācija 6 solis - atlikušo mežu klasifikācja, echo=FALSE}
# Flatten and clean the kalk_tips column
output_combine$kalk_tips <- sapply(output_combine$kalk_tips, function(x) {
  if (is.list(x)) {
    # Unlist to extract values from nested lists
    x <- unlist(x)
  }
  if (length(x) > 1) {
    # If multiple values exist, take the first one
    x <- x[1]
  }
  # Trim any leading/trailing whitespace
  x <- trimws(x)
  return(as.character(x))  # Ensure it's a character string
})

# Re-verify the unique values
unique_values <- unique(output_combine$kalk_tips)
print(unique_values)

# Initialize counters
jaukts_mezi_count <- 0
replaced_count <- 0

output_combine$kalk_tips <- apply(output_combine, 1, function(row) {
  # Ensure row values are characters
  kalk_tips <- trimws(as.character(row["kalk_tips"]))  # Trim any leading/trailing spaces
  skuj_proc <- as.numeric(row["Skuj_proc"])
  plat_proc <- as.numeric(row["Plat_proc"])
  shaurl_proc <- as.numeric(row["Shaur_proc"])
  
  # Check if already classified as "Jaukts mežs"
  if (kalk_tips == "Jaukts mežs") {
    # Increment counter for kept "Jaukts mežs" values
    assign("jaukts_mezi_count", jaukts_mezi_count + 1, envir = .GlobalEnv)
    return(kalk_tips)  # Keep the existing classification
  }
  
  # Check if the difference between any two percentages is greater than 20
  diff_skuj_plat <- abs(skuj_proc - plat_proc) > 20
  diff_skuj_shaurl <- abs(skuj_proc - shaurl_proc) > 20
  diff_plat_shaurl <- abs(plat_proc - shaurl_proc) > 20
  
  # If the difference is greater than 20 for any pair of values, proceed
  if (diff_skuj_plat | diff_skuj_shaurl | diff_plat_shaurl) {
    # Determine the highest value among the three
    max_value <- max(skuj_proc, plat_proc, shaurl_proc, na.rm = TRUE)
    
    # Increment counter for replaced values
    assign("replaced_count", replaced_count + 1, envir = .GlobalEnv)
    
    # Assign the forest type based on the highest value
    if (max_value == skuj_proc) {
      return("Skujkoku mežs")
    } else if (max_value == plat_proc) {
      return("Platlapju mežs")
    } else if (max_value == shaurl_proc) {
      return("Šaurlapju mežs")
    }
  }
  
  # If no conditions are met, return the original value
  return(kalk_tips)
})

# Print summary
cat("Found", jaukts_mezi_count, "'Jaukts mežs' values and kept them.\n")
cat("Replaced", replaced_count, "existing values with new classifications.\n")


```
<br> Pēc šīs klasifikācijas ir redzams, ka datu kopā paliek 1054 character(0) vērtības - tie meži, kuros vērtības ir visos 3 laukos un starpība ir mazāka par 20. Tie klasificējami kā jauktie meži.
```{r 14 / 15 mežu klasifikācija 7. solis - character(0) klasifikācija, echo=FALSE}
# Identify rows with character(0) in kalk_tips
char0_indices <- which(output_combine$kalk_tips == "character(0)")

# Debugging: Count the number of such rows
char0_count <- length(char0_indices)

# Replace character(0) values with "Jaukts mežs"
output_combine$kalk_tips[char0_indices] <- "Jaukts mežs"

# Print debugging message
cat("Found", char0_count, "character(0) fields and replaced with 'Jaukts mežs'.\n")

```
<br> Klasifikācija pabeigta. Pārbaudu rezultātus divos veidos - apskatos kategoriju vērtības datu kopā (nodrošinu, ka visi meži ir klasificēti atbilstoši nosacījumiem) un apskatos primitīvu statistiku (vidējās vērtības) katram mežu tipam. Pēc koku seguma vidējām vērtībām un mežu poligonu savstarpējās attiecības nosaku, ka rezultāti ir ticami un turpmāko apstrādi neveicu.  
```{r 15 / 15 mežu klasifikācija 8. solis - klasifikācijas pārbaude, echo=FALSE}
# Get unique values from the kalk_tips column
unique_values <- unique(output_combine$kalk_tips)

# Optional: If you want to see how many of each value exist
table_values <- table(output_combine$kalk_tips)
print(table_values)

# Create a summary function
summarize_kalk_tips <- function(data) {
  # Create an empty list to store summaries
  summaries <- list()
  
  # Get unique values in kalk_tips
  unique_values <- unique(data$kalk_tips)
  
  # Loop through each unique value
  for (value in unique_values) {
    # Subset data for the current kalk_tips value
    subset_data <- data[data$kalk_tips == value, ]
    
    # Calculate statistics
    shaur_mean <- mean(as.numeric(subset_data$Shaur_proc), na.rm = TRUE)
    skuj_mean <- mean(as.numeric(subset_data$Skuj_proc), na.rm = TRUE)
    plat_mean <- mean(as.numeric(subset_data$Plat_proc), na.rm = TRUE)
    max_diff <- max(abs(c(shaur_mean - skuj_mean, 
                          shaur_mean - plat_mean, 
                          skuj_mean - plat_mean)), na.rm = TRUE)
    
    a_value_mean <- mean(as.numeric(subset_data$A), na.rm = TRUE)
    
    # Store the summary
    summaries[[value]] <- list(
      Shaur_mean = shaur_mean,
      Skuj_mean = skuj_mean,
      Plat_mean = plat_mean,
      Max_diff = max_diff,
      A_mean = a_value_mean
    )
  }
  
  # Convert to a data frame for better readability
  summary_df <- do.call(rbind, lapply(names(summaries), function(name) {
    c(Kalk_tips = name, summaries[[name]])
  }))
  rownames(summary_df) <- NULL
  
  return(as.data.frame(summary_df))
}

# Run the function and print the summary
summary_results <- summarize_kalk_tips(output_combine)
print(summary_results)

```