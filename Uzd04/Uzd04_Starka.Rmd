---
title: "Uzd04_Starka"
author: "Rūta Starka"
date: "2025-01-26"
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Informēju, ka renderēšanas ātruma palielināšanai, no šī markdown dokumenta esmu izņēmusi skripta daļas, kas pārliecinās par atsevišķu funkcijas elementu darbību, pirms funkcijas likšanas kopā. Pilnu rmd dokumentu pievienoju atevišķi, bet tas nav renderēts, lai taupītu laiku. Savukārt šis dokuments sākas jau ar saliktu funkciju.

# Sagatavošanās
Palaižu visas uzdevuma veikšanai nepieciešamās pakotnes.
```{r pakotnes, include=FALSE}
#ja nepieciešams install.packages("nosaukums")
library(sfarrow)
library(sf)
library(arrow)
library(terra)
library(tidyverse)
library(fasterize)
library(pryr)
library(doParallel)
library(parallel)
library(foreach)
library(bigstatsr)
```

# 1. Funkcijas izveide
Šī funkcija ir as faterize() pieeju, kas pēc nelielas optimizēšanas jau ir kļuvusi 2x ātrāka kā funkcijas sākotnējā versija, ko biju izveidojusi. Esmu iepriekš pārliecinājusies, ka atsevišķas funkcijas daļas ir strādājošas un dod nepieciešamo rezultātu.  Izmēģināju arī exactextract, kas ietaupīja pārvēršanu ar rast(), tomēr radās citas problēmas, tāpēc izvēlējos to šoreiz tālāk neizmantot.

Lieku kopā funkciju. 
```{r ManaFunkcija, cache=TRUE}
mana_funkcija=function(input_file){
  MVR_centrs = st_read_parquet(input_file)

  ref_rastrs10m=rast("../Uzd03/ref_rastrs/LV10m_10km.tif")
  ref_rastrs100m=rast("../Uzd03/ref_rastrs/LV100m_10km.tif")
  
  ref_rastrs10m_centrs = terra::crop(ref_rastrs10m,MVR_centrs)
  ref_rastrs100m_centrs = terra::crop(ref_rastrs100m,MVR_centrs)
  
  ref_rastrs10m_centrs2=raster::raster(ref_rastrs10m_centrs)
  
  priedes=MVR_centrs%>%filter(s10 == 1)

  priedes_rastrs10m=fasterize(priedes,ref_rastrs10m_centrs2,background=0)

  priedes2_rastrs10m = rast(priedes_rastrs10m)

  priedes2_rastrs10m[is.na(ref_rastrs10m_centrs)] = NA
  
  output_dir = "../Uzd04/"
  file_name = tools::file_path_sans_ext(basename(input_file))
  output_filename = paste0(output_dir, file_name, "_priedes.tif")  
  
  priedes100=resample(priedes2_rastrs10m,ref_rastrs100m_centrs,
                      method="average",
                      filename=output_filename,
                      overwrite=TRUE)
}

```


Apskatīšu cik daudz laika patērē šī funkcija, paralēli vērojot atmiņas patēriņu.
```{r funkcijasLaiks1, cache=TRUE}
input_file_path <- "../Uzd02/centrs_kopa2.parquet"

funkcijas_laiks=system.time({
  mana_funkcija(input_file_path)
})

print(funkcijas_laiks)
```

Kā redzams, funkcija ir diezgan palēna, atrākais rezultāts, ko ieguvu, izpildot vairākas reizes ir 166,28 sekundes, kas ir apmēram 2,77 minūtes (katru reizi šo funkciju izpildot no jauna, laiks nedaudz variē). Funkcijas laikā tika izmantots viens CPU kodols, RAM patēriņš svārstījās starp 6-8 GB, maksimumā sasniedzot 18,5 GB. 

# 3. Virsmežniecības nodaļas kā atevišķi faili

Sākumā sagatavošu katras nodaļas datus kā atsevišķu geoparquet failu. 

```{r nodaluSlanuSagatavosana, message=FALSE, warning=FALSE, cache=TRUE}

nodala2651 = st_read(dsn="../Uzd02/VMD_MVR_centra",layer="nodala2651")
st_write_parquet(nodala2651, dsn="../Uzd02/VMD_MVR_centra/nodala2651.parquet")

nodala2652 = st_read(dsn="../Uzd02/VMD_MVR_centra",layer="nodala2652")
st_write_parquet(nodala2652, dsn="../Uzd02/VMD_MVR_centra/nodala2652.parquet")

nodala2653 = st_read(dsn="../Uzd02/VMD_MVR_centra",layer="nodala2653")
st_write_parquet(nodala2653, dsn="../Uzd02/VMD_MVR_centra/nodala2653.parquet")

nodala2654 = st_read(dsn="../Uzd02/VMD_MVR_centra",layer="nodala2654")
st_write_parquet(nodala2654, dsn="../Uzd02/VMD_MVR_centra/nodala2654.parquet")

nodala2655 = st_read(dsn="../Uzd02/VMD_MVR_centra",layer="nodala2655")
st_write_parquet(nodala2655, dsn="../Uzd02/VMD_MVR_centra/nodala2655.parquet")

rm(nodala2651,nodala2652, nodala2653, nodala2654, nodala2655)
```


Tālāk pārbaudīšu, cik kodoli vispār ir pieejami datorā, uz kura strādāju (LU).

```{r pieejamieKodoli, cache=TRUE}
bigstatsr::nb_cores()
```
Ir pieejami 3 fiziskie kodoli.

Tagam mēģināšu palaist savu funkciju paralēlam darbam uz vairākiem kodoliem, pie reizes nomērot cik ātri tas notiek. Noteikšu, ka veicot funkcijas jāizmanto paralēli 2 kodoli (vienu no 3 pieejamiem atstājot brīvu). 

```{r darbs2kodoli, warning=FALSE, cache=TRUE}

# Failu ielasīšanas ceļi 
input_files <- c(
  "../Uzd02/VMD_MVR_centra/nodala2651.parquet",
  "../Uzd02/VMD_MVR_centra/nodala2652.parquet",
  "../Uzd02/VMD_MVR_centra/nodala2653.parquet",
  "../Uzd02/VMD_MVR_centra/nodala2654.parquet",
  "../Uzd02/VMD_MVR_centra/nodala2655.parquet"
)

# Kodolu klasera definēšana
num_cores <- nb_cores() - 1  
cl2 <- makeCluster(num_cores)
registerDoParallel(cl2)

# Paralēla funkcijas palaišana
funkcijas_laiks2=system.time({
  foreach(i = seq_along(input_files), .packages = c("terra", "dplyr","sfarrow","fasterize"), .export="mana_funkcija") %dopar% {
    file=input_files[i]
    mana_funkcija(file)
  }
})

# Atiestatu uz kodolu izmantošanu uz noklusējumu
stopCluster(cl2)

print(funkcijas_laiks2)
```
Palaižot funkciju uz diviem kodoliem, ieguvu rezultātu ātri - 102 sekundes, kas ir 1,7 minūtes. RAM patēriņš izpildes laikā svārstījās ap 6-7GB, maksimums 14,6 GB.

# 4. Izpilde uz viena kodola

Tagad pārveidošu to pašu kodu, nosakot darba veikšanu uz tieši vienu. 
```{r darbs1kodols, warning=FALSE, cache=TRUE}

# Viena kodola klasera definēšana
cl1 <- makeCluster(1)
registerDoParallel(cl1)

# Funkcijas palaišana
funkcijas_laiks_1=system.time({
  foreach(i = seq_along(input_files), .packages = c("terra", "dplyr","sfarrow","fasterize"), .export="mana_funkcija") %dopar% {
    file=input_files[i]
    mana_funkcija(file)
  }
})

# Atiestatu kodolu izmantošanu uz noklusējumu
stopCluster(cl1)

# apskatu funkcijas izpildes laiku
print(funkcijas_laiks_1)
```
Funkcijas izpilde prasīja 141,56 sek (2,35 min). Funkcijas izpildes laikā RAM patēriņš bija diezgan stabils, svārstījās līdzīgi ap 6-7GB, bet maksimālais patēriņš samazinājās uz 9,7 GB. Tomēr jau redzams, ka uz pusi ilgāks laiks bija nepieciešams, lai funkciju veiktu, kas ir nozīmīgi, ja būtu milzīgs datu apjoms.

# 5. Funkcijas palaišana uz vairāk kā diviem kodoliem
Pamēģināšu tagad uz visiem trīs kodoliem. 
 
```{r darbs3kodoli, warning=FALSE, cache=TRUE}
#iztīru atmiņu, citādi saņemu kļūdas paziņojumu par nepietiekamu RAM
gc()

# Trīs kodolu klasera definēšana
cl3 <- makeCluster(3)
registerDoParallel(cl3)

# Paralēla funkcijas palaišana
funkcijas_laiks_3=system.time({
  foreach(i = seq_along(input_files), .packages = c("terra", "dplyr","sfarrow","fasterize"), .export="mana_funkcija") %dopar% {
    file=input_files[i]
    mana_funkcija(file)
  }
})

# Atiestatu kodolu izmantošanu uz noklusējumu
stopCluster(cl3)

# apskatu funkcijas izpildes laiku
print(funkcijas_laiks_3)
```
Un tagad jau ātrums arvien labāks - jau neticamas 77 sekundes (1,28 min), tomēr jāpiezīmē, ka šeit jau bija pirms tam jāveic atmiņas tīrīšana ar gc() pirms uzdevuma veikšanas, lai neiegūtu  "std::bad_alloc" paziņojumu par nepietiekamu RAM. Tā patēriņš bija jau vēl augstāks kā uz 2 kodoliem, patstāvīgi grozoties ap 8-10 GB, maksimumā jau ejot pāri 18GB. 

Kā pēdējo pamēģināju arī notiekt darbu uz 4 kodoliem, tomēr tur jau tomēr sākas problēmas, sistēma avarēja, kļūdas paziņojums par atmiņas trūkumu (Error in { : task 1 failed - "std::bad_alloc"), kas šķiet loģiski, ņemot vērā, ka ir tikai 3 fiziskie kodoli.

Iztīru R vidi. 
```{r tirisana, warning=FALSE, cache=TRUE}
rm(cl1, cl2, cl3,
   funkcijas_laiks,
   funkcijas_laiks_1,
   funkcijas_laiks2,
   funkcijas_laiks_3)
```


# Secinājumi
Šis uzdevums man liek domāt, ka darbību veikšana uz paralēliem kodoliem ir ātrāks risinājums, tomēr tas ir stabils tikai līdz zināmai robežai. Ideālā gadījumā, tieši piecu geoparket failu apstrādāšana caur funkciju, izmantojot piecus kodolus būtu visātrākais risinājums, tomēr tā nav (jāuzmanās ar atšķirību starp detectCores un num_Cores(), kas man sagādāja problēmas, sākotnēji domājot, ka datoram ir 6 fiziskie kodoli). Limitējot darbības tā, lai viens fiziskais kodols paliek brīvs, rada ātru (ne visātrāko), bet stabilu risinājumu. Visātrākais, tomēr nestabils risinājums, tika iegūts palaižot funkciju uz visiem trīs kodoliem (vairākas reizes ieguvu paziņojumu "Error in { : task 1 failed - "std::bad_alloc", ko atrisināju ar gc() pirms funkcijas). 
