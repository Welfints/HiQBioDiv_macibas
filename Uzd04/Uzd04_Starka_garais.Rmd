---
title: "Uzd04_Starka"
author: "Rūta Starka"
date: "2025-01-26"
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Šī ir garā skripta versija, kas satur sagatavošanās daļu - atsevišķu funkcijas elementu darbības pārbaudi (Chunk 3-7), kā arī nestrādājošu skripta daļu par automatizētu geoparquet failu sagatavošanu no shapefailiem (Chunk13). 

#Sagatavošanās
Palaižu visas uzdevuma veikšanai nepieciešamās pakotnes.
```{r pakotnes, cache=TRUE, include=FALSE}
#ja nepieciešams install.packages("nosaukums")
library(sfarrow)
library(sf)
library(arrow)
library(terra)
library(tidyverse)
library(fasterize)
library(pryr)
library(doParallel)
library(foreach)

```


Ielasu 2. uzdevumā izveidoto centra virsmežniecības geoparquet slāni kā arī 10 un 100 m  references slāņus, ko apgriežu atbilstoši centra virsmežniecības apjomam un pārvēršu no terra par raster objektiem.
```{r MVR ielasisana, cache=TRUE, message=FALSE}

MVR_centrs = st_read_parquet("D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/centrs_kopa2.parquet")

ref_rastrs10m=rast("D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd03/ref_rastrs/LV10m_10km.tif")
ref_rastrs10m_centrs = terra::crop(ref_rastrs10m,MVR_centrs)
ref_rastrs10m_centrs2=raster::raster(ref_rastrs10m_centrs)

ref_rastrs100m=rast("D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd03/ref_rastrs/LV100m_10km.tif")
ref_rastrs100m_centrs = terra::crop(ref_rastrs100m,MVR_centrs)

```

Tālāk izmēģināšu asevišķas funkcijas daļas, pirms lieku tās kopā. 
Vispirms uztaisīšu jaunu objektu, kur no MVR centra mežnieciecības atlasīšu mežaudzes, kurās valdošā koku suga ir priede, tātad laukā s10=="1". Tad šo atlasi rasterizēju, klasificēju vērtības laukos, kuros nav priedes atbilstoši uzdevuma nosacījumiem un pārbaudu vizuāli. Secinu, ka šī daļa ir sanākusi.
```{r priežu rasterizēšana, cache=TRUE, message=FALSE}

priedes=MVR_centrs%>%filter(s10 == 1)
priedes_rastrs10m=fasterize(priedes,ref_rastrs10m_centrs2,background=0)

priedes2_rastrs10m=rast(priedes_rastrs10m)
priedes2_rastrs10m[is.na(ref_rastrs10m_centrs)] = NA 

plot(priedes2_rastrs10m)
```
Tagad izmēģināšu daļu, kas pārvērš šo 10m rastru par 100m rastru atbilsoši referencei. Papildus, nepieciešams, lai tas satur informāciju par priežu īpatsvaru, tātad jāizmanto metode "sum". Pārbaudu vizuāli un secinu, ka viss ir kā plānots.

```{r rastra izšķirtspējas samazināšana, cache=TRUE, message=FALSE}
priedes100=resample(priedes2_rastrs10m,ref_rastrs100m_centrs,method="sum")
plot(priedes100)
```

Un kā pēdējo izmēģināšu saglabāšanas funkciju, šoreiz izvēloties to saglabāt ar IN1U kodējumu, jo tas, balstoties uz iepriekšējo uzdevumu, aizņem vismazāk vietas. 
Papildus, ģenerēju izvades faila nosaukumu (šim izmantoju chatgpt).
```{r saglabāšana, cache=TRUE}
input_file_path="D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/centrs_kopa2.parquet"

nosaukums_gen = function(input_file) {
  file_name = tools::file_path_sans_ext(basename(input_file))
  output_dir = "D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd04/" 
  output_filename = paste0(output_dir, file_name, "_priedes.tif")
  return(output_filename)
}

rezultats=nosaukums_gen(input)

writeRaster(priedes100, filename=rezultats,datatype = "INT1U", overwrite=TRUE)
```

Tagad, kad esmu pārliecinājusies, ka atsevišķas funkcijas daļas ir strādājošas, varu novākt izveidotos objektus, jo tie tiks ielasīti un veidoti iekš funckijas, tie R vidē nav atsevišķi nepieciešami. 
```{r tīrīšana pēc pārbaudes, cache=TRUE, include=FALSE, warning=FALSE}
rm(MVR_centrs, 
   ref_rastrs10m, 
   ref_rastrs10m_centrs, 
   ref_rastrs10m_centrs2, 
   ref_rastrs100m, 
   ref_rastrs100m_centrs, 
   priedes, 
   priedes_rastrs10m, 
   priedes2_rastrs10m, 
   priedes100, 
   input_file_path,
   nosaukums_gen,
   rezultats)
```


# 1. Funkcijas izveide
Tagad, kad esmu pārliecinājusies, ka atsevišķas funkcijas daļas ir strādājošas un dod nepieciešamo rezultātu, varu likt kopā. 

```{r mana_funkcija, cache=TRUE}
  
mana_funkcija=function(input_file){
  MVR_centrs = st_read_parquet(input_file)

  ref_rastrs10m=rast("D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd03/ref_rastrs/LV10m_10km.tif")
  ref_rastrs100m=rast("D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd03/ref_rastrs/LV100m_10km.tif")
  
  ref_rastrs10m_centrs = terra::crop(ref_rastrs10m,MVR_centrs)
  ref_rastrs100m_centrs = terra::crop(ref_rastrs100m,MVR_centrs)
  
  ref_rastrs10m_centrs2=raster::raster(ref_rastrs10m_centrs)
  
  priedes=MVR_centrs%>%filter(s10 == 1)
  priedes_rastrs10m=fasterize(priedes,ref_rastrs10m_centrs2,background=0)
  priedes2_rastrs10m=rast(priedes_rastrs10m)
  
  priedes2_rastrs10m[is.na(ref_rastrs10m_centrs)] = NA 
  
  priedes100=resample(priedes2_rastrs10m,ref_rastrs100m_centrs,method="sum")
  
  output_dir = "D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd04/"
  file_name = tools::file_path_sans_ext(basename(input_file))
  output_filename = paste0(output_dir, file_name, "_priedes.tif")

  writeRaster(priedes100, filename=output_filename,datatype = "INT1U", overwrite=TRUE)
}

```

Parbaudu, cik daudz operatīvās aizņem šī funkcija, ielasot apvienotos centra virsmežniecības datus.
P.S. laikam dēļ tā, ka izmantoju remote desktop, izsaucot task manager es varu apskatīt sava privātā datora procesus, nevis tā, ko izmantoju attālināti, līdz ar to, lai atbildētu uz jautājumiem par atmiņas lietojumu, jāizmanto komandrindas. No saskarnē pieejamās informācijas - tieši pirms komandas palaišanas R vidē lietoti 2,79 GB, funkcijas laikā RAM lietojums svārstoties palielinās līdz maksimumam 19,74 GB. Ļoti priecājos, ka šo nedaru uz sava datora ar 8GB RAMu.Tomēr es gribu izteikt savas aizdomas, ka šī funkcija, kas mēra RAM lietojumu, pati tērē diezgan daudz operatīvās atmiņas, jo tā paņēma manuprāt vairāk laika, ka zemāk esošais skripts, kas mēra funkcijas laiku, un arī funkcijas laika mērīšanas laikā augstākais atmiņas lietojums, kas parādījās R vides saskatnē bija ~17 GB.

```{r funkcijas RAM pārbaude, cache=TRUE}

RAMlietojums <- function(input_file) {
  initial_memory <- mem_used()
  mana_funkcija(input_file)
  final_memory <- mem_used()
  memory_used <- final_memory - initial_memory
  return(memory_used)
}

input_file_path <- "D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/centrs_kopa2.parquet"
RAMs=RAMlietojums(input_file_path)

print(paste("RAM lietojums izpildot 'mana_funkcija':", (RAMs/(1024^2)), "MB")) 

```

Šis iegūtais rezultāts, manuprāt neatspoguļo visu patiesību par atbiņas lietojumu, tas laikam mēra tikai R sesijas patērēto RAMu, nevis kopā ar sistēmu. Vai tik tur nebija jāpbūt ap 15 GB.
Katrā ziņā RAM šī uzdevuma veikšanai pietika (bet bija tuvu pārslodzei).

Noņemu ar atmiņas mērījumu saistītās komandrindas:
```{r tirisana, cache=TRUE, include=FALSE}
rm(RAMs, RAMlietojums)
```


Lai nu kā, tālāk apskatīšu cik daudz laika patērē šī funkcija. 
```{r funkcijas laika pārbaude, cache=TRUE}
input_file_path <- "D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/centrs_kopa2.parquet"

funkcijas_laiks=system.time({
  mana_funkcija(input_file_path)
})

print(funkcijas_laiks)
```

Kā redzams, funkcija ir diezgan lēna, atrākais rezultāts, ko ieguvu, izpildot vairākas reizes ir 378,65 sekundes, kas ir apmēram 6,3 minūtes (katru reizi šo funkciju izpildot no jauna, laiks nedaudz variē, citreiz izpildot ir 506.87 sekundes, kas jau ir ievērojami vairāk). 

Šādi es neredzu informāciju par izmantotajiem kodoliem, bet balstoties uz uzdevuma aprakstu pieņemu, ka teorētiski vajadzētu izmantot vienu kodolu, jo nav iestatīts citādi. 

# 3. Virsmežniecības nodaļas kā atevišķi faili

Sākumā sagatavošu katras nodaļas datus kā atsevišķu geoparquet failu. Te jāpiemin, ka mēģināju to automatizēt, bet saskāros ar problēmām. Zemāk ir skripts, kuru izlaidu renderējot, bet atstāju šeit. Funkcija automatizētai shapefailu konvertēšanai geoparquet formātā ar automatizētu nosaukuma izveidi rezultējās kļūdas paziņojumā sakarā ar formātu atpazīšanas problēmu. 

Garais, bet strādājošais risinājums:
```{r nodaļu slāņu sagatavošana 1, message=FALSE, warning=FALSE, cache=TRUE, include=FALSE}

nodala2651 = st_read(dsn="D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra",layer="nodala2651")
st_write_parquet(nodala2651, dsn="D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra/nodala2651.parquet")

nodala2652 = st_read(dsn="D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra",layer="nodala2652")
st_write_parquet(nodala2652, dsn="D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra/nodala2652.parquet")

nodala2653 = st_read(dsn="D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra",layer="nodala2653")
st_write_parquet(nodala2653, dsn="D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra/nodala2653.parquet")

nodala2654 = st_read(dsn="D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra",layer="nodala2654")
st_write_parquet(nodala2654, dsn="D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra/nodala2654.parquet")

nodala2655 = st_read(dsn="D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra",layer="nodala2655")
st_write_parquet(nodala2655, dsn="D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra/nodala2655.parquet")

rm(nodala2651,nodala2652, nodala2653, nodala2654, nodala2655)
```

Smalkais, bet nestrādājošais risinājums (neteikšu gan, ka tas būtu īsāks): 
```{r automatizētas konvertēšanas FAILS, eval=FALSE, cache=TRUE, include=FALSE}
shape_to_parquet <- function(shapefile_paths, output_dir) {
    for (shapefile in shapefile_paths) {
    sf_data <- st_read(shapefile)
    shapefile_name <- tools::file_path_sans_ext(basename(shapefile))
    geoparquet_filename <- file.path(output_dir, paste0(shapefile_name, ".parquet"))
    arrow::write_parquet(sf_data, geoparquet_filename)
    }}

# Norādu, kur atrodas ielasāmie faili, un kur likt uzrakstītos failus. Norādu garās direktoras, jo tā nav šī skripta darba direktorija.

shapefile_paths = c("D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra/nodala2651.shp", 
               "D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra/nodala2652.shp",
               "D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra/nodala2653.shp",
               "D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra/nodala2654.shp",
               "D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra/nodala2655.shp")

output_dir = "D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra"

#Visbeidzot palaižu šo funkciju
shape_to_parquet(shapefile_paths, output_dir)

#kļūdas paziņojums
Error:
! Can't infer Arrow data type from object inheriting from XY / MULTIPOLYGON / sfg
Backtrace:
  1. global shape_to_parquet(shapefile_paths, output_dir)
 31. arrow:::infer_type.default(`<XY>`, from_array_infer_type = TRUE)
```

Tālāk pārbaudīšu, cik kodoli vispār ir pieejami datorā, uz kura strādāju (LU).

```{r pieejamie kodoli, cache=TRUE}

detectCores()
```
Ir pieejami 6 kodoli. 

Tagam mēģināšu palaist savu funkciju paralēlam darbam uz vairākiem kodoliem, pie reizes nomērot cik ātri tas notiek. Noteikšu, ka veicot funkcijas jāizmanto paralēli 5 kodoli (vienu no 6 pieejamiem atstājot brīvu). 

```{r paralēla 5 kodolu iestatīšana, eval=FALSE, warning=FALSE, cache=TRUE, include=FALSE}

# Failu ielasīšanas ceļi (garie, jo neatrodas šajā wd)
input_files <- c(
  "D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra/nodala2651.parquet",
  "D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra/nodala2652.parquet",
  "D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra/nodala2653.parquet",
  "D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra/nodala2654.parquet",
  "D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra/nodala2655.parquet"
)

# Kodolu klasera definēšana
num_cores <- detectCores() - 1  
cl5 <- makeCluster(num_cores)
registerDoParallel(cl5)

# Paralēla funkcijas palaišana
funkcijas_laiks_par=system.time({
  results <- foreach(file = input_files, .packages = c("terra", "dplyr","sfarrow","fasterize"), .export="mana_funkcija") %dopar% {
    mana_funkcija(file)
  }
})

# Atiestatu uz kodolu izmantošanu uz noklusējumu
stopCluster(cl5)
```

Izpildot augstāk redzamās komandrindas R sesija vairākas reizes avarēja, un vairākas reizes ieguvu paziņojumu "Error in { : task 1 failed - "std::bad_alloc"
Timing stopped at: 0.27 0.08 47.53", kas nozīmē, ka datoram tomēr pietrūkst RAMs, lai veiktu šīs darbības uz pieciem kodoliem vienlaicīgi. To jau varēja arī nojaust, vērojot atmiņas saskarni R vidē, kas brīdināja par tās pārslodzi. 

#4 Izpilde uz viena kodola

Tagad pārveidošu to pašu kodu, nosakot nevis paralēli visu pieejamos(-1) kodolus, bet tieši vienu. 
```{r darba uz 1 kodola iestatīšana, warning=FALSE, cache=TRUE}

# Failu ielasīšanas ceļi (jādefinē, jo iepriekšējo chunk izlaidu no renderēšanas)
input_files <- c(
  "D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra/nodala2651.parquet",
  "D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra/nodala2652.parquet",
  "D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra/nodala2653.parquet",
  "D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra/nodala2654.parquet",
  "D:/Users/RutaStarka/Desktop/Git local Ruuta/HiQBioDiv_macibas/Uzd02/VMD_MVR_centra/nodala2655.parquet"
)

# Viena kodola klasera definēšana
cl1 <- makeCluster(1)
registerDoParallel(cl1)

# Paralēla funkcijas palaišana
funkcijas_laiks_1=system.time({
  results <- foreach(file = input_files, .packages = c("terra", "dplyr","sfarrow","fasterize"), .export="mana_funkcija") %dopar% {
    mana_funkcija(file)
  }
})

# Atiestatu kodolu izmantošanu uz noklusējumu
stopCluster(cl1)

# apskatu funkcijas izpildes laiku
print(funkcijas_laiks_1)
```
Funkcijas izpildes sākumā R vidē bija 1,14 GB, funkcijas izpildes laikā tas saglabājās ap šo vērtību. Funkcijas izpilde prasīja 340,5 sek (5,68 min), bet ne reizi sistēma neavarēja.

#5 Funkcijas palaišana uz diviem vai vairāk kodoliem
Ņemot vērā RAM ierobežojumus, mēģināšu palaist uz tieši 2 kodoliem. 
Rediģēju kodu un izmēģinu. 

```{r darba uz 2 kodoliem iestatīšana, warning=FALSE, cache=TRUE}

# Divu kodolu klasera definēšana
cl2 <- makeCluster(2)
registerDoParallel(cl2)

# Paralēla funkcijas palaišana
funkcijas_laiks_2=system.time({
  results <- foreach(file = input_files, .packages = c("terra", "dplyr","sfarrow","fasterize"), .export="mana_funkcija") %dopar% {
    mana_funkcija(file)
  }
})

# Atiestatu kodolu izmantošanu uz noklusējumu
stopCluster(cl2)

# apskatu funkcijas izpildes laiku
print(funkcijas_laiks_2)
```

 Funkcijas palaišanas sākumā R vidē bija 1,26 GB. Izpildes laikā tā palielinājās līdz 1,85 GB, ne miņas no pārslodzes. Ātrums samazinājās teju divkārt (uz 228,68 sek, kas ir 3,8 min), kas ir pilnīgi loģiski. Tas mani iedrošina pamēģināt uz trīs kodoliem. 
 
```{r darba uz 3 kodoliem iestatīšana, warning=FALSE, cache=TRUE}

# Divu kodolu klasera definēšana
cl3 <- makeCluster(3)
registerDoParallel(cl3)

# Paralēla funkcijas palaišana
funkcijas_laiks_3=system.time({
  results <- foreach(file = input_files, .packages = c("terra", "dplyr","sfarrow","fasterize"), .export="mana_funkcija") %dopar% {
    mana_funkcija(file)
  }
})

# Atiestatu kodolu izmantošanu uz noklusējumu
stopCluster(cl3)

# apskatu funkcijas izpildes laiku
print(funkcijas_laiks_3)
```
Un tagad jau no 1,3 GB līdz 2,02 GB atmiņas lietojums, bet ātrums arvien labāks - jau 173 sekundes (2,99 min). 

Nu tad pēdējais, pamēģināšu uz 4 kodoliem.
```{r darba uz 4 kodoliem iestatīšana, eval=FALSE, warning=FALSE, cache=TRUE, include=FALSE}

# Divu kodolu klasera definēšana
cl4 <- makeCluster(4)
registerDoParallel(cl4)

# Paralēla funkcijas palaišana
funkcijas_laiks_4=system.time({
  results <- foreach(file = input_files, .packages = c("terra", "dplyr","sfarrow","fasterize"), .export="mana_funkcija") %dopar% {
    mana_funkcija(file)
  }
})

# Atiestatu kodolu izmantošanu uz noklusējumu
stopCluster(cl4)

# apskatu funkcijas izpildes laiku
print(funkcijas_laiks_4)
```
Nu, uz 4 kodoliem jau tomēr sākas problēmas, sistēma avarēja, kļūdas paziņojums par atmiņas trūkumu (Error in { : task 1 failed - "std::bad_alloc"). Skatīt secinājumus.

Iztīru R vidi. 
```{r beigu tīrīšana, cache=TRUE}
rm(cl1, cl2, cl3,
   funkcijas_laiks,
   funkcijas_laiks_1,
   funkcijas_laiks_2,
   funkcijas_laiks_3)
```


#secinājumi
Šis uzdevums man liek domāt, ka darbību veikšana uz paralēliem kodoliem ir ātrāks risinājums, tomēr tas ir stabils tikai līdz zināmai robežai. Ideālā gadījumā, tieši piecu geoparket failu apstrādāšana caur funkciju, izmantojot piecus kodolus būtu visātrākais risinājums, tomēr tā nav. Acīmredzot visi pieci tiek vienlaicīgi ielasīti operatīvajā atmiņā un tieši tas ātri vien rada problēmas.Savukārt limitējot darbības tā, lai divi līdz trīs kodoli paliek brīvi, rada ātru, bet stabilu risinājumu.
Iegūtie rezultāti līdz trīs kodolu paralēlai izmantošanai ir loģiski. 
